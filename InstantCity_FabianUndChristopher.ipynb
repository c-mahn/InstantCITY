{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "W8tn0zdsa7yi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klone nach 'InstantCity'...\n",
      "remote: Enumerating objects: 166, done.\u001b[K\n",
      "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
      "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
      "remote: Total 166 (delta 6), reused 3 (delta 3), pack-reused 148\u001b[K\n",
      "Empfange Objekte: 100% (166/166), 11.39 MiB | 16.69 MiB/s, fertig.\n",
      "Löse Unterschiede auf: 100% (24/24), fertig.\n"
     ]
    }
   ],
   "source": [
    "# Clone Repository of InstantCity\n",
    "!rm -rf ./InstantCity/\n",
    "!git clone https://github.com/ualsg/InstantCity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6hD0N7VPbNza"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hdd/repository/InstantCITY/InstantCity\n"
     ]
    }
   ],
   "source": [
    "# Change working directory to InstantCity\n",
    "%cd InstantCity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "L2SslF3hbQ2W"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\t\t images       options\t   run_engine.py  util\n",
      "environment.yml  LICENSE.txt  __pycache__  test.py\n",
      "fid.py\t\t models       README.md    train.py\n"
     ]
    }
   ],
   "source": [
    "# What's inside\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xhoCvN93M-1P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<p align=\"center\">\n",
      "  <a href=\"https://ual.sg/\">\n",
      "    <img src=\"images/logo.jpg\" alt=\"Logo\">\n",
      "  </a>\n",
      "  <h3 align=\"center\">InstantCITY: Synthesising morphologically accurate geospatial data for urban form analysis, transfer, and quality control</h3>\n",
      "  <a >\n",
      "    <img src=\"images/Pipeline.png\" alt=\"Logo\">\n",
      "  </a>\n",
      "</p>\n",
      "\n",
      "This is the official repo of InstantCITY, a Geospatial Data Translation model for urban form analysis, transfer, and quality control.\n",
      "\n",
      "## Running InstantCITY \n",
      "\n",
      "### 1. Install prerequisites\n",
      "\n",
      "Use `environment.yml` to create a conda environment for GANmapper\n",
      "\n",
      "  ```sh\n",
      "  conda env create -f environment.yml\n",
      "  conda activate IC\n",
      "  ```\n",
      "\n",
      "### 2. Download weights\n",
      "The weights files are available on figshare in the Checkpoints folder.\n",
      "\n",
      "```https://doi.org/10.6084/m9.figshare.15103128.v1```\n",
      "\n",
      "Place the `Checkpoints` folder in the repo.\n",
      "### 3. Prediction\n",
      "Predictions can be carried out by running the following sample code. The name of the city depends on the name of each dataset.\n",
      "\n",
      " ```sh\n",
      " python test.py --name <model_name> --dataroot <path to input XYZ tile dir with street networks> \n",
      "  ```\n",
      "\n",
      "Testing an area in New York:\n",
      " ```sh\n",
      " python test.py --name NY15 --dataroot ./datasets/Test/NY/input/15 \n",
      "  ```\n",
      "\n",
      "Testing an area in Singapore:\n",
      " ```sh\n",
      "python test.py --name SG15 --dataroot ./datasets/Test/SG/input/15 \n",
      "  ```\n",
      "\n",
      "Testing an area in London:\n",
      " ```sh\n",
      "python test.py --name London15 --dataroot ./datasets/Test/London/input/15 \n",
      "  ```\n",
      "\n",
      "The result will be produced in XYZ directories in `./results/<cityname>/test_latest/images/fake`\n",
      "\n",
      "### 4. Style Transfer\n",
      "Transfering the style of one city to another, in this case, a model trained in New York City is used to predict the morphology in Detroit.\n",
      " ```sh\n",
      "python test.py --name NY15 --dataroot ./datasets/Transfer/Detroit/input/15\n",
      "  ```\n",
      "\n",
      "Or transfering the urban texture of Jakarta to the street network of Manila\n",
      "\n",
      " ```sh\n",
      "python test.py --name Jakarta15 --dataroot ./datasets/Transfer/Manila/input/15\n",
      "  ```\n",
      "\n",
      "You can choose to visualise the tiles in QGIS using a local WMTS server.\n",
      "For example, use the following url and choose Zoom 15 only.\n",
      "```\n",
      "file:///D:/InstantCITY//datasets/Test/SG//fake//{z}//{x}//{y}.png\n",
      "```\n",
      "\n",
      "### 4. Metrics and Vectorization\n",
      "\n",
      "Please see the jupyter notebook in `datasets/Metric.ipynb` for FID score computation and vectorization.\n",
      "\n",
      "## Paper\n",
      "\n",
      "A [paper](https://doi.org/10.1016/j.isprsjprs.2022.11.005) about the work was published in _ISPRS Journal of Photogrammetry and Remote Sensing_, and it is available open access [here](https://ual.sg/publication/2023-ijprs-instantcity/2023-ijprs-instantcity.pdf).\n",
      "\n",
      "If you use this work in a scientific context, please cite this article.\n",
      "\n",
      "Wu AN, Biljecki F (2023): InstantCITY: Synthesising morphologically accurate geospatial data for urban form analysis, transfer, and quality control. ISPRS Journal of Photogrammetry and Remote Sensing, 195: 90-104. doi:10.1016/j.isprsjprs.2022.11.005\n",
      "\n",
      "```\n",
      "@article{2023_ijprs_instantcity,\n",
      "  author = {Wu, Abraham Noah and Biljecki, Filip},\n",
      "  doi = {10.1016/j.isprsjprs.2022.11.005},\n",
      "  journal = {ISPRS Journal of Photogrammetry and Remote Sensing},\n",
      "  pages = {90-104},\n",
      "  title = {InstantCITY: Synthesising morphologically accurate geospatial data for urban form analysis, transfer, and quality control},\n",
      "  volume = {195},\n",
      "  year = {2023}\n",
      "}\n",
      "```\n",
      "\n",
      "## License\n",
      "\n",
      "Distributed under the MIT License. See `LICENSE` for more information.\n",
      "\n",
      "<!-- ## Citation\n",
      "\n",
      "If you like this work and would like to use it in a scientific context, please cite this article.\n",
      "```\n",
      "@misc{wu2021ganmapper,\n",
      "      title={GANmapper: geographical content filling}, \n",
      "      author={Abraham Noah Wu and Filip Biljecki},\n",
      "      year={2021},\n",
      "      eprint={2108.04232},\n",
      "      archivePrefix={arXiv},\n",
      "      primaryClass={cs.CV}\n",
      "}\n",
      "``` -->\n",
      "\n",
      "## Acknowledgements\n",
      "\n",
      "InstantCity is made possible by using the following packages\n",
      "\n",
      "* [PyTorch](https://pytorch.org/)\n",
      "* [GeoPandas](https://geopandas.org/)\n",
      "* [Robosat](https://github.com/mapbox/robosat) - \n",
      " mask to feature function is borrowed from robosat\n",
      "* [GANmapper](https://github.com/ualsg/GANmapper) - \n",
      "Data processing scripts are borrowed from GANmapper\n",
      "\n",
      "* [pix2pixHD](https://github.com/NVIDIA/pix2pixHD) - \n",
      "Model Architecture is heavily borrowed from the awesome repo by [tcwang0509](https://github.com/tcwang0509)"
     ]
    }
   ],
   "source": [
    "!cat ./README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EVDTl8iMcz0B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.3\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "F0NgPJbPrzae"
   },
   "outputs": [],
   "source": [
    "# !pip install condacolab\n",
    "# import condacolab\n",
    "# condacolab.install()\n",
    "# !conda --version\n",
    "# !which conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "H6YwbdKTc1g0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31merror\u001b[0m: \u001b[1mexternally-managed-environment\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m This environment is externally managed\n",
      "\u001b[31m╰─>\u001b[0m To install Python packages system-wide, try 'pacman -S\n",
      "\u001b[31m   \u001b[0m python-xyz', where xyz is the package you are trying to\n",
      "\u001b[31m   \u001b[0m install.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Arch-packaged Python package,\n",
      "\u001b[31m   \u001b[0m create a virtual environment using 'python -m venv path/to/venv'.\n",
      "\u001b[31m   \u001b[0m Then use path/to/venv/bin/python and path/to/venv/bin/pip.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Arch packaged Python application,\n",
      "\u001b[31m   \u001b[0m it may be easiest to use 'pipx install xyz', which will manage a\n",
      "\u001b[31m   \u001b[0m virtual environment for you. Make sure you have python-pipx\n",
      "\u001b[31m   \u001b[0m installed via pacman.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\n",
      "\u001b[1;36mhint\u001b[0m: See PEP 668 for the detailed specification.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mexternally-managed-environment\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m This environment is externally managed\n",
      "\u001b[31m╰─>\u001b[0m To install Python packages system-wide, try 'pacman -S\n",
      "\u001b[31m   \u001b[0m python-xyz', where xyz is the package you are trying to\n",
      "\u001b[31m   \u001b[0m install.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Arch-packaged Python package,\n",
      "\u001b[31m   \u001b[0m create a virtual environment using 'python -m venv path/to/venv'.\n",
      "\u001b[31m   \u001b[0m Then use path/to/venv/bin/python and path/to/venv/bin/pip.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Arch packaged Python application,\n",
      "\u001b[31m   \u001b[0m it may be easiest to use 'pipx install xyz', which will manage a\n",
      "\u001b[31m   \u001b[0m virtual environment for you. Make sure you have python-pipx\n",
      "\u001b[31m   \u001b[0m installed via pacman.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\n",
      "\u001b[1;36mhint\u001b[0m: See PEP 668 for the detailed specification.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mexternally-managed-environment\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m This environment is externally managed\n",
      "\u001b[31m╰─>\u001b[0m To install Python packages system-wide, try 'pacman -S\n",
      "\u001b[31m   \u001b[0m python-xyz', where xyz is the package you are trying to\n",
      "\u001b[31m   \u001b[0m install.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Arch-packaged Python package,\n",
      "\u001b[31m   \u001b[0m create a virtual environment using 'python -m venv path/to/venv'.\n",
      "\u001b[31m   \u001b[0m Then use path/to/venv/bin/python and path/to/venv/bin/pip.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Arch packaged Python application,\n",
      "\u001b[31m   \u001b[0m it may be easiest to use 'pipx install xyz', which will manage a\n",
      "\u001b[31m   \u001b[0m virtual environment for you. Make sure you have python-pipx\n",
      "\u001b[31m   \u001b[0m installed via pacman.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\n",
      "\u001b[1;36mhint\u001b[0m: See PEP 668 for the detailed specification.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mexternally-managed-environment\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m This environment is externally managed\n",
      "\u001b[31m╰─>\u001b[0m To install Python packages system-wide, try 'pacman -S\n",
      "\u001b[31m   \u001b[0m python-xyz', where xyz is the package you are trying to\n",
      "\u001b[31m   \u001b[0m install.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Arch-packaged Python package,\n",
      "\u001b[31m   \u001b[0m create a virtual environment using 'python -m venv path/to/venv'.\n",
      "\u001b[31m   \u001b[0m Then use path/to/venv/bin/python and path/to/venv/bin/pip.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Arch packaged Python application,\n",
      "\u001b[31m   \u001b[0m it may be easiest to use 'pipx install xyz', which will manage a\n",
      "\u001b[31m   \u001b[0m virtual environment for you. Make sure you have python-pipx\n",
      "\u001b[31m   \u001b[0m installed via pacman.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\n",
      "\u001b[1;36mhint\u001b[0m: See PEP 668 for the detailed specification.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mexternally-managed-environment\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m This environment is externally managed\n",
      "\u001b[31m╰─>\u001b[0m To install Python packages system-wide, try 'pacman -S\n",
      "\u001b[31m   \u001b[0m python-xyz', where xyz is the package you are trying to\n",
      "\u001b[31m   \u001b[0m install.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Arch-packaged Python package,\n",
      "\u001b[31m   \u001b[0m create a virtual environment using 'python -m venv path/to/venv'.\n",
      "\u001b[31m   \u001b[0m Then use path/to/venv/bin/python and path/to/venv/bin/pip.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Arch packaged Python application,\n",
      "\u001b[31m   \u001b[0m it may be easiest to use 'pipx install xyz', which will manage a\n",
      "\u001b[31m   \u001b[0m virtual environment for you. Make sure you have python-pipx\n",
      "\u001b[31m   \u001b[0m installed via pacman.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\n",
      "\u001b[1;36mhint\u001b[0m: See PEP 668 for the detailed specification.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mexternally-managed-environment\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m This environment is externally managed\n",
      "\u001b[31m╰─>\u001b[0m To install Python packages system-wide, try 'pacman -S\n",
      "\u001b[31m   \u001b[0m python-xyz', where xyz is the package you are trying to\n",
      "\u001b[31m   \u001b[0m install.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Arch-packaged Python package,\n",
      "\u001b[31m   \u001b[0m create a virtual environment using 'python -m venv path/to/venv'.\n",
      "\u001b[31m   \u001b[0m Then use path/to/venv/bin/python and path/to/venv/bin/pip.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Arch packaged Python application,\n",
      "\u001b[31m   \u001b[0m it may be easiest to use 'pipx install xyz', which will manage a\n",
      "\u001b[31m   \u001b[0m virtual environment for you. Make sure you have python-pipx\n",
      "\u001b[31m   \u001b[0m installed via pacman.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\n",
      "\u001b[1;36mhint\u001b[0m: See PEP 668 for the detailed specification.\n"
     ]
    }
   ],
   "source": [
    "# install modules\n",
    "!pip install pathlib\n",
    "!pip install dominate\n",
    "!pip install scipy\n",
    "!pip install torch\n",
    "!pip install Pillow\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "xm8J-81Ufr55"
   },
   "outputs": [],
   "source": [
    "# Connect to Google Drive to retreive GANmapper_Data\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# !ls /content/drive/MyDrive/GANmapper_Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5yhJx8jvM1Jw"
   },
   "outputs": [],
   "source": [
    "# Copy the testing data from GANmapper_Data\n",
    "# !cp -r /content/drive/MyDrive/GANmapper_Data/checkpoints /content/InstantCity/\n",
    "# !cp -r /content/drive/MyDrive/GANmapper_Data/datasets /content/InstantCity/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip GANmapper data\n",
    "!unzip -q -o ../GANmapper\\ Data.zip\n",
    "# And move it to the parent folder\n",
    "!cp -r ./GANmapper\\ Data/checkpoints .\n",
    "!cp -r ./GANmapper\\ Data/datasets ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Q4dkk1_lvtNV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Data Processing.ipynb'   Exp4\n",
      "Jakarta  Jakarta17  LA\tParis  Singapore\n"
     ]
    }
   ],
   "source": [
    "# What's inside datasets?\n",
    "!ls ./datasets\n",
    "!ls ./datasets/Exp4/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "eCgUc5X0M6iB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp1  Exp2  Exp3\n",
      "Jakarta  LA  Singapore\n",
      "latest_net_D.pth  loss_log.txt\ttrain_opt.txt\n",
      "latest_net_G.pth  test_opt.txt\tweb\n"
     ]
    }
   ],
   "source": [
    "# What's inside checkpoints?\n",
    "!ls ./checkpoints/\n",
    "!ls ./checkpoints/Exp3/\n",
    "!ls ./checkpoints/Exp3/Singapore/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "R4ILmjXtvLW0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying data...\n",
      "Copy complete.\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "# Copy Test-dataset\n",
    "!mkdir ./datasets/Test\n",
    "print(\"Copying data...\")\n",
    "!cp -r ./datasets/Exp4/Singapore/Source/* ./datasets/Test/\n",
    "print(\"Copy complete.\")\n",
    "!ls ./datasets/Test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "yCXyitqGJsTX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying data...\n",
      "Copy complete.\n",
      "latest_net_D.pth  loss_log.txt\ttrain_opt.txt\n",
      "latest_net_G.pth  test_opt.txt\tweb\n"
     ]
    }
   ],
   "source": [
    "# Copy Test-model\n",
    "!mkdir ./checkpoints/SG15\n",
    "print(\"Copying data...\")\n",
    "!cp -r ./checkpoints/Exp3/Singapore/* ./checkpoints/SG15/\n",
    "print(\"Copy complete.\")\n",
    "!ls ./checkpoints/SG15/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "VzrL9VEw67Mq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: das Verzeichnis „./training_data“ kann nicht angelegt werden: Die Datei existiert bereits\n"
     ]
    }
   ],
   "source": [
    "# Fix mistakes, that are located in the repo\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Copy modified python-scripts\n",
    "!cp ../modified_files/train.py ./\n",
    "!cp ../modified_files/test.py ./\n",
    "!cp ../modified_files/pix2pixHD_model.py ./models/\n",
    "!cp ../modified_files/models.py ./models/\n",
    "\n",
    "# Copy training images to the training directory\n",
    "!mkdir ./training_data\n",
    "!cp -r ./datasets/Exp4/Singapore/Source/* ./training_data/train_A/\n",
    "!cp -r ./datasets/Exp4/Singapore/Target/* ./training_data/train_B/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "VrHnqJ_jbTQz"
   },
   "outputs": [],
   "source": [
    "# What's in the test script?\n",
    "# !cat test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "gW9hGeFV0w2D"
   },
   "outputs": [],
   "source": [
    "# What are the test's parameters?\n",
    "# !cat options/test_options.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Oci-_Z9lSWOn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Options -------------\n",
      "batchSize: 1\n",
      "beta1: 0.5\n",
      "checkpoints_dir: ./checkpoints\n",
      "continue_train: False\n",
      "data_type: 32\n",
      "dataroot: ./training_data\n",
      "debug: False\n",
      "display_freq: 100\n",
      "display_winsize: 512\n",
      "feat_num: 3\n",
      "fineSize: 512\n",
      "fp16: False\n",
      "gpu_ids: [0]\n",
      "input_nc: 3\n",
      "instance_feat: False\n",
      "isTrain: True\n",
      "label_feat: False\n",
      "label_nc: 0\n",
      "lambda_feat: 10.0\n",
      "loadSize: 1024\n",
      "load_features: False\n",
      "load_pretrain: \n",
      "local_rank: 0\n",
      "lr: 0.0002\n",
      "max_dataset_size: inf\n",
      "model: pix2pixHD\n",
      "nThreads: 2\n",
      "n_blocks_global: 9\n",
      "n_blocks_local: 3\n",
      "n_clusters: 10\n",
      "n_downsample_E: 4\n",
      "n_downsample_global: 4\n",
      "n_layers_D: 3\n",
      "n_local_enhancers: 1\n",
      "name: custom_model\n",
      "ndf: 64\n",
      "nef: 16\n",
      "netG: global\n",
      "ngf: 64\n",
      "niter: 60\n",
      "niter_decay: 40\n",
      "niter_fix_global: 0\n",
      "no_flip: False\n",
      "no_ganFeat_loss: False\n",
      "no_html: False\n",
      "no_instance: 1\n",
      "no_lsgan: False\n",
      "no_vgg_loss: False\n",
      "norm: instance\n",
      "num_D: 2\n",
      "output_nc: 3\n",
      "phase: train\n",
      "pool_size: 0\n",
      "print_freq: 100\n",
      "resize_or_crop: scale_width\n",
      "save_epoch_freq: 10\n",
      "save_latest_freq: 1000\n",
      "serial_batches: False\n",
      "tf_log: False\n",
      "use_dropout: False\n",
      "verbose: False\n",
      "which_epoch: latest\n",
      "-------------- End ----------------\n",
      "CustomDatasetDataLoader\n",
      "dataset [AlignedDataset] was created\n",
      "#training images = 50\n",
      "GlobalGenerator(\n",
      "  (model): Sequential(\n",
      "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (11): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (14): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (17): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (18): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (19): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (20): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (21): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (22): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (23): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (24): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (25): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (26): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (29): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (30): ReLU(inplace=True)\n",
      "    (31): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (32): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (33): ReLU(inplace=True)\n",
      "    (34): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (35): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (36): ReLU(inplace=True)\n",
      "    (37): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (38): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (39): Tanh()\n",
      "  )\n",
      ")\n",
      "MultiscaleDiscriminator(\n",
      "  (scale0_layer0): Sequential(\n",
      "    (0): Conv2d(6, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale0_layer1): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale0_layer2): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale0_layer3): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale0_layer4): Sequential(\n",
      "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (scale1_layer0): Sequential(\n",
      "    (0): Conv2d(6, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale1_layer1): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale1_layer2): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale1_layer3): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale1_layer4): Sequential(\n",
      "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (downsample): AvgPool2d(kernel_size=3, stride=2, padding=[1, 1])\n",
      ")\n",
      "/usr/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /home/christopher/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n",
      "100%|████████████████████████████████████████| 548M/548M [00:12<00:00, 44.3MB/s]\n",
      "create web directory ./checkpoints/custom_model/web...\n",
      "Traceback (most recent call last):\n",
      "  File \"/hdd/repository/InstantCITY/InstantCity/train.py\", line 82, in <module>\n",
      "    losses, generated = model(Variable(data['label']), Variable(data['inst']), \n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py\", line 169, in forward\n",
      "    return self.module(*inputs[0], **kwargs[0])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/hdd/repository/InstantCITY/InstantCity/models/pix2pixHD_model.py\", line 190, in forward\n",
      "    loss_G_VGG = self.criterionVGG(fake_image, real_image) * self.opt.lambda_feat\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/hdd/repository/InstantCITY/InstantCity/models/networks.py\", line 123, in forward\n",
      "    loss += self.weights[i] * self.criterion(x_vgg[i], y_vgg[i].detach())        \n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/site-packages/torch/nn/modules/loss.py\", line 101, in forward\n",
      "    return F.l1_loss(input, target, reduction=self.reduction)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/site-packages/torch/nn/functional.py\", line 3264, in l1_loss\n",
      "    return torch._C._nn.l1_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB (GPU 0; 11.76 GiB total capacity; 9.43 GiB already allocated; 185.00 MiB free; 9.71 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    }
   ],
   "source": [
    "# Run the test of model\n",
    "!python train.py --name custom_model --dataroot ./training_data\n",
    "# Rename folder in /content/InstantCity/datasets/Exp4/Singapore into \"train_A\" and \"train_B\", to work with it\n",
    "# Remember the model must be saved at \"/content/InstantCity/checkpoints/SG15/\"\n",
    "# !python test.py --name SG15 --dataroot ./datasets/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kGobJtf8LN9U"
   },
   "outputs": [],
   "source": [
    "!ls /content/InstantCity/fake\\\\16/51688/\n",
    "from PIL import Image\n",
    "im = Image.open(\"/content/InstantCity/fake\\\\16/51688/32519.png\")\n",
    "im.show()\n",
    "!cp /content/InstantCity/fake\\\\"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
