{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "W8tn0zdsa7yi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klone nach 'InstantCity'...\n",
      "remote: Enumerating objects: 166, done.\u001b[K\n",
      "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
      "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
      "remote: Total 166 (delta 6), reused 3 (delta 3), pack-reused 148\u001b[K\n",
      "Empfange Objekte: 100% (166/166), 11.39 MiB | 23.61 MiB/s, fertig.\n",
      "Löse Unterschiede auf: 100% (24/24), fertig.\n"
     ]
    }
   ],
   "source": [
    "# Clone Repository of InstantCity\n",
    "!rm -rf ./InstantCity/\n",
    "!git clone https://github.com/ualsg/InstantCity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6hD0N7VPbNza"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hdd/repository/InstantCITY/InstantCity\n"
     ]
    }
   ],
   "source": [
    "# Change working directory to InstantCity\n",
    "%cd InstantCity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "L2SslF3hbQ2W"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\t\t images       options\t   run_engine.py  util\r\n",
      "environment.yml  LICENSE.txt  __pycache__  test.py\r\n",
      "fid.py\t\t models       README.md    train.py\r\n"
     ]
    }
   ],
   "source": [
    "# What's inside\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "xhoCvN93M-1P"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "<p align=\"center\">\r\n",
      "  <a href=\"https://ual.sg/\">\r\n",
      "    <img src=\"images/logo.jpg\" alt=\"Logo\">\r\n",
      "  </a>\r\n",
      "  <h3 align=\"center\">InstantCITY: Synthesising morphologically accurate geospatial data for urban form analysis, transfer, and quality control</h3>\r\n",
      "  <a >\r\n",
      "    <img src=\"images/Pipeline.png\" alt=\"Logo\">\r\n",
      "  </a>\r\n",
      "</p>\r\n",
      "\r\n",
      "This is the official repo of InstantCITY, a Geospatial Data Translation model for urban form analysis, transfer, and quality control.\r\n",
      "\r\n",
      "## Running InstantCITY \r\n",
      "\r\n",
      "### 1. Install prerequisites\r\n",
      "\r\n",
      "Use `environment.yml` to create a conda environment for GANmapper\r\n",
      "\r\n",
      "  ```sh\r\n",
      "  conda env create -f environment.yml\r\n",
      "  conda activate IC\r\n",
      "  ```\r\n",
      "\r\n",
      "### 2. Download weights\r\n",
      "The weights files are available on figshare in the Checkpoints folder.\r\n",
      "\r\n",
      "```https://doi.org/10.6084/m9.figshare.15103128.v1```\r\n",
      "\r\n",
      "Place the `Checkpoints` folder in the repo.\r\n",
      "### 3. Prediction\r\n",
      "Predictions can be carried out by running the following sample code. The name of the city depends on the name of each dataset.\r\n",
      "\r\n",
      " ```sh\r\n",
      " python test.py --name <model_name> --dataroot <path to input XYZ tile dir with street networks> \r\n",
      "  ```\r\n",
      "\r\n",
      "Testing an area in New York:\r\n",
      " ```sh\r\n",
      " python test.py --name NY15 --dataroot ./datasets/Test/NY/input/15 \r\n",
      "  ```\r\n",
      "\r\n",
      "Testing an area in Singapore:\r\n",
      " ```sh\r\n",
      "python test.py --name SG15 --dataroot ./datasets/Test/SG/input/15 \r\n",
      "  ```\r\n",
      "\r\n",
      "Testing an area in London:\r\n",
      " ```sh\r\n",
      "python test.py --name London15 --dataroot ./datasets/Test/London/input/15 \r\n",
      "  ```\r\n",
      "\r\n",
      "The result will be produced in XYZ directories in `./results/<cityname>/test_latest/images/fake`\r\n",
      "\r\n",
      "### 4. Style Transfer\r\n",
      "Transfering the style of one city to another, in this case, a model trained in New York City is used to predict the morphology in Detroit.\r\n",
      " ```sh\r\n",
      "python test.py --name NY15 --dataroot ./datasets/Transfer/Detroit/input/15\r\n",
      "  ```\r\n",
      "\r\n",
      "Or transfering the urban texture of Jakarta to the street network of Manila\r\n",
      "\r\n",
      " ```sh\r\n",
      "python test.py --name Jakarta15 --dataroot ./datasets/Transfer/Manila/input/15\r\n",
      "  ```\r\n",
      "\r\n",
      "You can choose to visualise the tiles in QGIS using a local WMTS server.\r\n",
      "For example, use the following url and choose Zoom 15 only.\r\n",
      "```\r\n",
      "file:///D:/InstantCITY//datasets/Test/SG//fake//{z}//{x}//{y}.png\r\n",
      "```\r\n",
      "\r\n",
      "### 4. Metrics and Vectorization\r\n",
      "\r\n",
      "Please see the jupyter notebook in `datasets/Metric.ipynb` for FID score computation and vectorization.\r\n",
      "\r\n",
      "## Paper\r\n",
      "\r\n",
      "A [paper](https://doi.org/10.1016/j.isprsjprs.2022.11.005) about the work was published in _ISPRS Journal of Photogrammetry and Remote Sensing_, and it is available open access [here](https://ual.sg/publication/2023-ijprs-instantcity/2023-ijprs-instantcity.pdf).\r\n",
      "\r\n",
      "If you use this work in a scientific context, please cite this article.\r\n",
      "\r\n",
      "Wu AN, Biljecki F (2023): InstantCITY: Synthesising morphologically accurate geospatial data for urban form analysis, transfer, and quality control. ISPRS Journal of Photogrammetry and Remote Sensing, 195: 90-104. doi:10.1016/j.isprsjprs.2022.11.005\r\n",
      "\r\n",
      "```\r\n",
      "@article{2023_ijprs_instantcity,\r\n",
      "  author = {Wu, Abraham Noah and Biljecki, Filip},\r\n",
      "  doi = {10.1016/j.isprsjprs.2022.11.005},\r\n",
      "  journal = {ISPRS Journal of Photogrammetry and Remote Sensing},\r\n",
      "  pages = {90-104},\r\n",
      "  title = {InstantCITY: Synthesising morphologically accurate geospatial data for urban form analysis, transfer, and quality control},\r\n",
      "  volume = {195},\r\n",
      "  year = {2023}\r\n",
      "}\r\n",
      "```\r\n",
      "\r\n",
      "## License\r\n",
      "\r\n",
      "Distributed under the MIT License. See `LICENSE` for more information.\r\n",
      "\r\n",
      "<!-- ## Citation\r\n",
      "\r\n",
      "If you like this work and would like to use it in a scientific context, please cite this article.\r\n",
      "```\r\n",
      "@misc{wu2021ganmapper,\r\n",
      "      title={GANmapper: geographical content filling}, \r\n",
      "      author={Abraham Noah Wu and Filip Biljecki},\r\n",
      "      year={2021},\r\n",
      "      eprint={2108.04232},\r\n",
      "      archivePrefix={arXiv},\r\n",
      "      primaryClass={cs.CV}\r\n",
      "}\r\n",
      "``` -->\r\n",
      "\r\n",
      "## Acknowledgements\r\n",
      "\r\n",
      "InstantCity is made possible by using the following packages\r\n",
      "\r\n",
      "* [PyTorch](https://pytorch.org/)\r\n",
      "* [GeoPandas](https://geopandas.org/)\r\n",
      "* [Robosat](https://github.com/mapbox/robosat) - \r\n",
      " mask to feature function is borrowed from robosat\r\n",
      "* [GANmapper](https://github.com/ualsg/GANmapper) - \r\n",
      "Data processing scripts are borrowed from GANmapper\r\n",
      "\r\n",
      "* [pix2pixHD](https://github.com/NVIDIA/pix2pixHD) - \r\n",
      "Model Architecture is heavily borrowed from the awesome repo by [tcwang0509](https://github.com/tcwang0509)"
     ]
    }
   ],
   "source": [
    "!cat ./README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "EVDTl8iMcz0B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.11.3\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "F0NgPJbPrzae"
   },
   "outputs": [],
   "source": [
    "# !pip install condacolab\n",
    "# import condacolab\n",
    "# condacolab.install()\n",
    "# !conda --version\n",
    "# !which conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "H6YwbdKTc1g0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31merror\u001b[0m: \u001b[1mexternally-managed-environment\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m This environment is externally managed\n",
      "\u001b[31m╰─>\u001b[0m To install Python packages system-wide, try 'pacman -S\n",
      "\u001b[31m   \u001b[0m python-xyz', where xyz is the package you are trying to\n",
      "\u001b[31m   \u001b[0m install.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Arch-packaged Python package,\n",
      "\u001b[31m   \u001b[0m create a virtual environment using 'python -m venv path/to/venv'.\n",
      "\u001b[31m   \u001b[0m Then use path/to/venv/bin/python and path/to/venv/bin/pip.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Arch packaged Python application,\n",
      "\u001b[31m   \u001b[0m it may be easiest to use 'pipx install xyz', which will manage a\n",
      "\u001b[31m   \u001b[0m virtual environment for you. Make sure you have python-pipx\n",
      "\u001b[31m   \u001b[0m installed via pacman.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\n",
      "\u001b[1;36mhint\u001b[0m: See PEP 668 for the detailed specification.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mexternally-managed-environment\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m This environment is externally managed\n",
      "\u001b[31m╰─>\u001b[0m To install Python packages system-wide, try 'pacman -S\n",
      "\u001b[31m   \u001b[0m python-xyz', where xyz is the package you are trying to\n",
      "\u001b[31m   \u001b[0m install.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Arch-packaged Python package,\n",
      "\u001b[31m   \u001b[0m create a virtual environment using 'python -m venv path/to/venv'.\n",
      "\u001b[31m   \u001b[0m Then use path/to/venv/bin/python and path/to/venv/bin/pip.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Arch packaged Python application,\n",
      "\u001b[31m   \u001b[0m it may be easiest to use 'pipx install xyz', which will manage a\n",
      "\u001b[31m   \u001b[0m virtual environment for you. Make sure you have python-pipx\n",
      "\u001b[31m   \u001b[0m installed via pacman.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\n",
      "\u001b[1;36mhint\u001b[0m: See PEP 668 for the detailed specification.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mexternally-managed-environment\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m This environment is externally managed\n",
      "\u001b[31m╰─>\u001b[0m To install Python packages system-wide, try 'pacman -S\n",
      "\u001b[31m   \u001b[0m python-xyz', where xyz is the package you are trying to\n",
      "\u001b[31m   \u001b[0m install.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Arch-packaged Python package,\n",
      "\u001b[31m   \u001b[0m create a virtual environment using 'python -m venv path/to/venv'.\n",
      "\u001b[31m   \u001b[0m Then use path/to/venv/bin/python and path/to/venv/bin/pip.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Arch packaged Python application,\n",
      "\u001b[31m   \u001b[0m it may be easiest to use 'pipx install xyz', which will manage a\n",
      "\u001b[31m   \u001b[0m virtual environment for you. Make sure you have python-pipx\n",
      "\u001b[31m   \u001b[0m installed via pacman.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\n",
      "\u001b[1;36mhint\u001b[0m: See PEP 668 for the detailed specification.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mexternally-managed-environment\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m This environment is externally managed\n",
      "\u001b[31m╰─>\u001b[0m To install Python packages system-wide, try 'pacman -S\n",
      "\u001b[31m   \u001b[0m python-xyz', where xyz is the package you are trying to\n",
      "\u001b[31m   \u001b[0m install.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Arch-packaged Python package,\n",
      "\u001b[31m   \u001b[0m create a virtual environment using 'python -m venv path/to/venv'.\n",
      "\u001b[31m   \u001b[0m Then use path/to/venv/bin/python and path/to/venv/bin/pip.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Arch packaged Python application,\n",
      "\u001b[31m   \u001b[0m it may be easiest to use 'pipx install xyz', which will manage a\n",
      "\u001b[31m   \u001b[0m virtual environment for you. Make sure you have python-pipx\n",
      "\u001b[31m   \u001b[0m installed via pacman.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\n",
      "\u001b[1;36mhint\u001b[0m: See PEP 668 for the detailed specification.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mexternally-managed-environment\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m This environment is externally managed\n",
      "\u001b[31m╰─>\u001b[0m To install Python packages system-wide, try 'pacman -S\n",
      "\u001b[31m   \u001b[0m python-xyz', where xyz is the package you are trying to\n",
      "\u001b[31m   \u001b[0m install.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Arch-packaged Python package,\n",
      "\u001b[31m   \u001b[0m create a virtual environment using 'python -m venv path/to/venv'.\n",
      "\u001b[31m   \u001b[0m Then use path/to/venv/bin/python and path/to/venv/bin/pip.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Arch packaged Python application,\n",
      "\u001b[31m   \u001b[0m it may be easiest to use 'pipx install xyz', which will manage a\n",
      "\u001b[31m   \u001b[0m virtual environment for you. Make sure you have python-pipx\n",
      "\u001b[31m   \u001b[0m installed via pacman.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\n",
      "\u001b[1;36mhint\u001b[0m: See PEP 668 for the detailed specification.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mexternally-managed-environment\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m This environment is externally managed\n",
      "\u001b[31m╰─>\u001b[0m To install Python packages system-wide, try 'pacman -S\n",
      "\u001b[31m   \u001b[0m python-xyz', where xyz is the package you are trying to\n",
      "\u001b[31m   \u001b[0m install.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Arch-packaged Python package,\n",
      "\u001b[31m   \u001b[0m create a virtual environment using 'python -m venv path/to/venv'.\n",
      "\u001b[31m   \u001b[0m Then use path/to/venv/bin/python and path/to/venv/bin/pip.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Arch packaged Python application,\n",
      "\u001b[31m   \u001b[0m it may be easiest to use 'pipx install xyz', which will manage a\n",
      "\u001b[31m   \u001b[0m virtual environment for you. Make sure you have python-pipx\n",
      "\u001b[31m   \u001b[0m installed via pacman.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\n",
      "\u001b[1;36mhint\u001b[0m: See PEP 668 for the detailed specification.\n"
     ]
    }
   ],
   "source": [
    "# install modules\n",
    "!pip install pathlib\n",
    "!pip install dominate\n",
    "!pip install scipy\n",
    "!pip install torch\n",
    "!pip install Pillow\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xm8J-81Ufr55"
   },
   "outputs": [],
   "source": [
    "# Connect to Google Drive to retreive GANmapper_Data\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# !ls /content/drive/MyDrive/GANmapper_Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "5yhJx8jvM1Jw"
   },
   "outputs": [],
   "source": [
    "# Copy the testing data from GANmapper_Data\n",
    "# !cp -r /content/drive/MyDrive/GANmapper_Data/checkpoints /content/InstantCity/\n",
    "# !cp -r /content/drive/MyDrive/GANmapper_Data/datasets /content/InstantCity/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip GANmapper data\n",
    "!unzip -q -o ../GANmapper\\ Data.zip\n",
    "# And move it to the parent folder\n",
    "!cp -r ./GANmapper\\ Data/checkpoints .\n",
    "!cp -r ./GANmapper\\ Data/datasets ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Q4dkk1_lvtNV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Data Processing.ipynb'   Exp4\n",
      "Jakarta  Jakarta17  LA\tParis  Singapore\n"
     ]
    }
   ],
   "source": [
    "# What's inside datasets?\n",
    "!ls ./datasets\n",
    "!ls ./datasets/Exp4/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "eCgUc5X0M6iB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp1  Exp2  Exp3\n",
      "Jakarta  LA  Singapore\n",
      "latest_net_D.pth  loss_log.txt\ttrain_opt.txt\n",
      "latest_net_G.pth  test_opt.txt\tweb\n"
     ]
    }
   ],
   "source": [
    "# What's inside checkpoints?\n",
    "!ls ./checkpoints/\n",
    "!ls ./checkpoints/Exp3/\n",
    "!ls ./checkpoints/Exp3/Singapore/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "R4ILmjXtvLW0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying data...\n",
      "Copy complete.\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "# Copy Test-dataset\n",
    "!mkdir ./datasets/Test\n",
    "print(\"Copying data...\")\n",
    "!cp -r ./datasets/Exp4/Singapore/Source/* ./datasets/Test/\n",
    "print(\"Copy complete.\")\n",
    "!ls ./datasets/Test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "yCXyitqGJsTX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying data...\n",
      "Copy complete.\n",
      "latest_net_D.pth  loss_log.txt\ttrain_opt.txt\n",
      "latest_net_G.pth  test_opt.txt\tweb\n"
     ]
    }
   ],
   "source": [
    "# Copy Test-model\n",
    "!mkdir ./checkpoints/SG15\n",
    "print(\"Copying data...\")\n",
    "!cp -r ./checkpoints/Exp3/Singapore/* ./checkpoints/SG15/\n",
    "print(\"Copy complete.\")\n",
    "!ls ./checkpoints/SG15/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "VzrL9VEw67Mq"
   },
   "outputs": [],
   "source": [
    "# Fix mistakes, that are located in the repo\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Copy modified python-scripts\n",
    "!cp ../modified_files/train.py ./\n",
    "!cp ../modified_files/test.py ./\n",
    "!cp ../modified_files/pix2pixHD_model.py ./models/\n",
    "!cp ../modified_files/models.py ./models/\n",
    "!cp ../modified_files/image_folder.py ./data/\n",
    "!cp ../modified_files/aligned_dataset.py ./data/\n",
    "\n",
    "# Copy training images to the training directory\n",
    "!mkdir ./training_data\n",
    "!cp -r ./datasets/Exp4/Singapore/Source/* ./training_data/train_A/\n",
    "!cp -r ./datasets/Exp4/Singapore/Target/* ./training_data/train_B/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "VrHnqJ_jbTQz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import time\r\n",
      "import os\r\n",
      "import numpy as np\r\n",
      "import torch\r\n",
      "from torch.autograd import Variable\r\n",
      "from collections import OrderedDict\r\n",
      "from subprocess import call\r\n",
      "import fractions\r\n",
      "from torch.cuda.amp import autocast, GradScaler\r\n",
      "\r\n",
      "\r\n",
      "def gcd(a, b):\r\n",
      "    \"\"\"Calculate the Greatest Common Divisor of a and b.\r\n",
      "\r\n",
      "    Unless b==0, the result will have the same sign as b (so that when\r\n",
      "    b is divided by it, the result comes out positive).\r\n",
      "    \"\"\"\r\n",
      "    while b:\r\n",
      "        a, b = b, a%b\r\n",
      "    return a\r\n",
      "\r\n",
      "def lcm(a,b): return abs(a * b)/gcd(a,b) if a and b else 0\r\n",
      "\r\n",
      "from options.train_options import TrainOptions\r\n",
      "from data.data_loader import CreateDataLoader\r\n",
      "from models.models import create_model\r\n",
      "import util.util as util\r\n",
      "from util.visualizer import Visualizer\r\n",
      "\r\n",
      "if __name__==\"__main__\":\r\n",
      "    scaler = GradScaler()\r\n",
      "    torch.cuda.empty_cache()\r\n",
      "    opt = TrainOptions().parse()\r\n",
      "    iter_path = os.path.join(opt.checkpoints_dir, opt.name, 'iter.txt')\r\n",
      "    if opt.continue_train:\r\n",
      "        try:\r\n",
      "            start_epoch, epoch_iter = np.loadtxt(iter_path , delimiter=',', dtype=int)\r\n",
      "        except:\r\n",
      "            start_epoch, epoch_iter = 1, 0\r\n",
      "        print('Resuming from epoch %d at iteration %d' % (start_epoch, epoch_iter))        \r\n",
      "    else:    \r\n",
      "        start_epoch, epoch_iter = 1, 0\r\n",
      "\r\n",
      "    opt.print_freq = lcm(opt.print_freq, opt.batchSize)    \r\n",
      "    if opt.debug:\r\n",
      "        # opt.display_freq = 1\r\n",
      "        # opt.print_freq = 1\r\n",
      "        opt.niter = 2910\r\n",
      "        opt.niter_decay = 2910\r\n",
      "        opt.nThreads = 30\r\n",
      "        # opt.max_dataset_size = 10\r\n",
      "        # opt.batchSize = 1\r\n",
      "\r\n",
      "    data_loader = CreateDataLoader(opt)\r\n",
      "    dataset = data_loader.load_data()\r\n",
      "    dataset_size = len(data_loader)\r\n",
      "    print('#training images = %d' % dataset_size)\r\n",
      "\r\n",
      "    model = create_model(opt)\r\n",
      "    visualizer = Visualizer(opt)\r\n",
      "    if opt.fp16:    \r\n",
      "        # from apex import amp\r\n",
      "        # model, [optimizer_G, optimizer_D] = amp.initialize(model, [model.optimizer_G, model.optimizer_D], opt_level='O1')             \r\n",
      "        model = torch.nn.DataParallel(model, device_ids=opt.gpu_ids)\r\n",
      "    else:\r\n",
      "        optimizer_G, optimizer_D = model.module.optimizer_G, model.module.optimizer_D\r\n",
      "\r\n",
      "    total_steps = (start_epoch-1) * dataset_size + epoch_iter\r\n",
      "\r\n",
      "    display_delta = total_steps % opt.display_freq\r\n",
      "    print_delta = total_steps % opt.print_freq\r\n",
      "    save_delta = total_steps % opt.save_latest_freq\r\n",
      "\r\n",
      "    for epoch in range(start_epoch, opt.niter + opt.niter_decay + 1):\r\n",
      "        torch.cuda.empty_cache()\r\n",
      "        epoch_start_time = time.time()\r\n",
      "        if epoch != start_epoch:\r\n",
      "            epoch_iter = epoch_iter % dataset_size\r\n",
      "        for i, data in enumerate(dataset, start=epoch_iter):\r\n",
      "            if total_steps % opt.print_freq == print_delta:\r\n",
      "                iter_start_time = time.time()\r\n",
      "            total_steps += opt.batchSize\r\n",
      "            epoch_iter += opt.batchSize\r\n",
      "\r\n",
      "            # whether to collect output images\r\n",
      "            save_fake = total_steps % opt.display_freq == display_delta\r\n",
      "\r\n",
      "            # ############## Forward Pass ######################\r\n",
      "            # losses, generated = model(Variable(data['label']), Variable(data['inst']), \r\n",
      "            #     Variable(data['image']), Variable(data['feat']), infer=save_fake)\r\n",
      "            \r\n",
      "            # Forward Pass\r\n",
      "            with autocast():\r\n",
      "                losses, generated = model(Variable(data['label']), Variable(data['inst']), \r\n",
      "                    Variable(data['image']), Variable(data['feat']), infer=save_fake)\r\n",
      "\r\n",
      "\r\n",
      "            # sum per device losses\r\n",
      "            losses = [ torch.mean(x) if not isinstance(x, int) else x for x in losses ]\r\n",
      "            loss_dict = dict(zip(model.module.loss_names, losses))\r\n",
      "\r\n",
      "            # calculate final loss scalar\r\n",
      "            loss_D = (loss_dict['D_fake'] + loss_dict['D_real']) * 0.5\r\n",
      "            loss_G = loss_dict['G_GAN'] + loss_dict.get('G_GAN_Feat',0) + loss_dict.get('G_VGG',0)\r\n",
      "\r\n",
      "            ############### Backward Pass ####################\r\n",
      "            # update generator weights\r\n",
      "            optimizer_G.zero_grad()\r\n",
      "            if opt.fp16:                                \r\n",
      "                # with amp.scale_loss(loss_G, optimizer_G) as scaled_loss: scaled_loss.backward()\r\n",
      "                # update generator weights\r\n",
      "                optimizer_G.zero_grad()\r\n",
      "                scaler.scale(loss_G).backward()\r\n",
      "                scaler.step(optimizer_G)\r\n",
      "                scaler.update()\r\n",
      "            else:\r\n",
      "                loss_G.backward()          \r\n",
      "            optimizer_G.step()\r\n",
      "\r\n",
      "            # update discriminator weights\r\n",
      "            optimizer_D.zero_grad()\r\n",
      "            if opt.fp16:                                \r\n",
      "                # with amp.scale_loss(loss_D, optimizer_D) as scaled_loss: scaled_loss.backward()\r\n",
      "                # update discriminator weights\r\n",
      "                optimizer_D.zero_grad()  \r\n",
      "                scaler.scale(loss_D).backward()\r\n",
      "                scaler.step(optimizer_D)\r\n",
      "                scaler.update()\r\n",
      "            else:\r\n",
      "                loss_D.backward()        \r\n",
      "            optimizer_D.step()        \r\n",
      "\r\n",
      "            ############## Display results and errors ##########\r\n",
      "            ### print out errors\r\n",
      "            if total_steps % opt.print_freq == print_delta:\r\n",
      "                errors = {k: v.data.item() if not isinstance(v, int) else v for k, v in loss_dict.items()}            \r\n",
      "                t = (time.time() - iter_start_time) / opt.print_freq\r\n",
      "                visualizer.print_current_errors(epoch, epoch_iter, errors, t)\r\n",
      "                visualizer.plot_current_errors(errors, total_steps)\r\n",
      "                #call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=memory.used,memory.free\"]) \r\n",
      "\r\n",
      "            ### display output images\r\n",
      "            if save_fake:\r\n",
      "                visuals = OrderedDict([('input_label', util.tensor2label(data['label'][0], opt.label_nc)),\r\n",
      "                                    ('synthesized_image', util.tensor2im(generated.data[0])),\r\n",
      "                                    ('real_image', util.tensor2im(data['image'][0]))])\r\n",
      "                visualizer.display_current_results(visuals, epoch, total_steps)\r\n",
      "\r\n",
      "            ### save latest model\r\n",
      "            if total_steps % opt.save_latest_freq == save_delta:\r\n",
      "                print('saving the latest model (epoch %d, total_steps %d)' % (epoch, total_steps))\r\n",
      "                model.module.save('latest')            \r\n",
      "                np.savetxt(iter_path, (epoch, epoch_iter), delimiter=',', fmt='%d')\r\n",
      "\r\n",
      "            if epoch_iter >= dataset_size:\r\n",
      "                break\r\n",
      "        \r\n",
      "        # end of epoch \r\n",
      "        iter_end_time = time.time()\r\n",
      "        print('End of epoch %d / %d \\t Time Taken: %d sec' %\r\n",
      "            (epoch, opt.niter + opt.niter_decay, time.time() - epoch_start_time))\r\n",
      "\r\n",
      "        ### save model for this epoch\r\n",
      "        if epoch % opt.save_epoch_freq == 0:\r\n",
      "            print('saving the model at the end of epoch %d, iters %d' % (epoch, total_steps))        \r\n",
      "            model.module.save('latest')\r\n",
      "            model.module.save(epoch)\r\n",
      "            np.savetxt(iter_path, (epoch+1, 0), delimiter=',', fmt='%d')\r\n",
      "\r\n",
      "        ### instead of only training the local enhancer, train the entire network after certain iterations\r\n",
      "        if (opt.niter_fix_global != 0) and (epoch == opt.niter_fix_global):\r\n",
      "            model.module.update_fixed_params()\r\n",
      "\r\n",
      "        ### linearly decay learning rate after certain iterations\r\n",
      "        if epoch > opt.niter:\r\n",
      "            model.module.update_learning_rate()\r\n"
     ]
    }
   ],
   "source": [
    "# What's in the test script?\n",
    "!cat train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "gW9hGeFV0w2D"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from .base_options import BaseOptions\r\n",
      "\r\n",
      "class TestOptions(BaseOptions):\r\n",
      "    def initialize(self):\r\n",
      "        BaseOptions.initialize(self)\r\n",
      "        self.parser.add_argument('--ntest', type=int, default=float(\"inf\"), help='# of test examples.')\r\n",
      "        self.parser.add_argument('--results_dir', type=str, default='./results/', help='saves results here.')\r\n",
      "        self.parser.add_argument('--aspect_ratio', type=float, default=1.0, help='aspect ratio of result images')\r\n",
      "        self.parser.add_argument('--phase', type=str, default='test', help='train, val, test, etc')\r\n",
      "        self.parser.add_argument('--which_epoch', type=str, default='latest', help='which epoch to load? set to latest to use latest cached model')\r\n",
      "        self.parser.add_argument('--how_many', type=int, default=5000, help='how many test images to run')       \r\n",
      "        self.parser.add_argument('--cluster_path', type=str, default='features_clustered_010.npy', help='the path for clustered results of encoded features')\r\n",
      "        self.parser.add_argument('--use_encoded_image', action='store_true', help='if specified, encode the real image to get the feature map')\r\n",
      "        self.parser.add_argument(\"--export_onnx\", type=str, help=\"export ONNX model to a given file\")\r\n",
      "        self.parser.add_argument(\"--engine\", type=str, help=\"run serialized TRT engine\")\r\n",
      "        self.parser.add_argument(\"--onnx\", type=str, help=\"run ONNX model via TRT\")        \r\n",
      "        self.isTrain = False\r\n"
     ]
    }
   ],
   "source": [
    "# What are the test's parameters?\n",
    "!cat ./options/test_options.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oci-_Z9lSWOn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Options -------------\n",
      "batchSize: 1\n",
      "beta1: 0.5\n",
      "checkpoints_dir: ./checkpoints\n",
      "continue_train: False\n",
      "data_type: 32\n",
      "dataroot: ./training_data\n",
      "debug: True\n",
      "display_freq: 100\n",
      "display_winsize: 512\n",
      "feat_num: 3\n",
      "fineSize: 512\n",
      "fp16: False\n",
      "gpu_ids: [0]\n",
      "input_nc: 3\n",
      "instance_feat: False\n",
      "isTrain: True\n",
      "label_feat: False\n",
      "label_nc: 0\n",
      "lambda_feat: 10.0\n",
      "loadSize: 1024\n",
      "load_features: False\n",
      "load_pretrain: \n",
      "local_rank: 0\n",
      "lr: 0.0002\n",
      "max_dataset_size: inf\n",
      "model: pix2pixHD\n",
      "nThreads: 2\n",
      "n_blocks_global: 9\n",
      "n_blocks_local: 3\n",
      "n_clusters: 10\n",
      "n_downsample_E: 4\n",
      "n_downsample_global: 4\n",
      "n_layers_D: 3\n",
      "n_local_enhancers: 1\n",
      "name: custom_model\n",
      "ndf: 64\n",
      "nef: 16\n",
      "netG: global\n",
      "ngf: 64\n",
      "niter: 60\n",
      "niter_decay: 40\n",
      "niter_fix_global: 0\n",
      "no_flip: False\n",
      "no_ganFeat_loss: False\n",
      "no_html: False\n",
      "no_instance: 1\n",
      "no_lsgan: False\n",
      "no_vgg_loss: False\n",
      "norm: instance\n",
      "num_D: 2\n",
      "output_nc: 3\n",
      "phase: train\n",
      "pool_size: 0\n",
      "print_freq: 100\n",
      "resize_or_crop: scale_width\n",
      "save_epoch_freq: 10\n",
      "save_latest_freq: 1000\n",
      "serial_batches: False\n",
      "tf_log: False\n",
      "use_dropout: False\n",
      "verbose: False\n",
      "which_epoch: latest\n",
      "-------------- End ----------------\n",
      "CustomDatasetDataLoader\n",
      "dataset [AlignedDataset] was created\n",
      "#training images = 25\n",
      "GlobalGenerator(\n",
      "  (model): Sequential(\n",
      "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (11): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (14): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (17): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (18): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (19): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (20): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (21): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (22): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (23): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (24): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace=True)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (25): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (26): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (29): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (30): ReLU(inplace=True)\n",
      "    (31): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (32): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (33): ReLU(inplace=True)\n",
      "    (34): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (35): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (36): ReLU(inplace=True)\n",
      "    (37): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (38): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (39): Tanh()\n",
      "  )\n",
      ")\n",
      "MultiscaleDiscriminator(\n",
      "  (scale0_layer0): Sequential(\n",
      "    (0): Conv2d(6, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale0_layer1): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale0_layer2): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale0_layer3): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale0_layer4): Sequential(\n",
      "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (scale1_layer0): Sequential(\n",
      "    (0): Conv2d(6, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale1_layer1): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale1_layer2): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale1_layer3): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (scale1_layer4): Sequential(\n",
      "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (downsample): AvgPool2d(kernel_size=3, stride=2, padding=[1, 1])\n",
      ")\n",
      "/usr/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create web directory ./checkpoints/custom_model/web...\n",
      "End of epoch 1 / 5820 \t Time Taken: 8 sec\n",
      "End of epoch 2 / 5820 \t Time Taken: 7 sec\n",
      "End of epoch 3 / 5820 \t Time Taken: 7 sec\n",
      "(epoch: 4, iters: 25, time: 0.301) G_GAN: 1.249 G_GAN_Feat: 16.081 G_VGG: 11.156 D_real: 0.466 D_fake: 0.487 \n",
      "End of epoch 4 / 5820 \t Time Taken: 7 sec\n",
      "End of epoch 5 / 5820 \t Time Taken: 7 sec\n",
      "End of epoch 6 / 5820 \t Time Taken: 7 sec\n",
      "End of epoch 7 / 5820 \t Time Taken: 7 sec\n",
      "(epoch: 8, iters: 25, time: 0.284) G_GAN: 0.633 G_GAN_Feat: 14.558 G_VGG: 6.941 D_real: 0.386 D_fake: 0.681 \n",
      "End of epoch 8 / 5820 \t Time Taken: 7 sec\n",
      "End of epoch 9 / 5820 \t Time Taken: 7 sec\n",
      "End of epoch 10 / 5820 \t Time Taken: 7 sec\n",
      "saving the model at the end of epoch 10, iters 250\n"
     ]
    }
   ],
   "source": [
    "# Run the test of model\n",
    "!python train.py --name custom_model --dataroot ./training_data --debug\n",
    "# Rename folder in /content/InstantCity/datasets/Exp4/Singapore into \"train_A\" and \"train_B\", to work with it\n",
    "# Remember the model must be saved at \"/content/InstantCity/checkpoints/SG15/\"\n",
    "# !python test.py --name SG15 --dataroot ./datasets/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kGobJtf8LN9U"
   },
   "outputs": [],
   "source": [
    "!ls /content/InstantCity/fake\\\\16/51688/\n",
    "from PIL import Image\n",
    "im = Image.open(\"/content/InstantCity/fake\\\\16/51688/32519.png\")\n",
    "im.show()\n",
    "!cp /content/InstantCity/fake\\\\"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
